{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from cvxpy import *\n",
    "from DTools import *\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.patches import Rectangle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path =r'../experiment_data2/' # use your path\n",
    "train_0 = pd.read_csv(path + \"train_0.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "train_1 = pd.read_csv(path + \"train_1.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "train_2 = pd.read_csv(path + \"train_2.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "train_3 = pd.read_csv(path + \"train_3.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "train_4 = pd.read_csv(path + \"train_4.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "test_0 = pd.read_csv(path + \"test_0.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "test_1 = pd.read_csv(path + \"test_1.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "test_2 = pd.read_csv(path + \"test_2.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "test_3 = pd.read_csv(path + \"test_3.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "test_4 = pd.read_csv(path + \"test_4.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "train_new_0 = pd.read_csv(path + \"train_new_0.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "train_new_1 = pd.read_csv(path + \"train_new_1.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "train_new_2 = pd.read_csv(path + \"train_new_2.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "train_new_3 = pd.read_csv(path + \"train_new_3.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "train_new_4 = pd.read_csv(path + \"train_new_4.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "test_new_0 = pd.read_csv(path + \"test_new_0.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "test_new_1 = pd.read_csv(path + \"test_new_1.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "test_new_2 = pd.read_csv(path + \"test_new_2.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "test_new_3 = pd.read_csv(path + \"test_new_3.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "test_new_4 = pd.read_csv(path + \"test_new_4.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "features = ['race','age_cat','c_charge_degree','priors_count','is_recid']\n",
    "D_features = ['race']\n",
    "Y_features = ['is_recid']\n",
    "X_features = ['age_cat', 'c_charge_degree','priors_count']\n",
    "\n",
    "TrainList=[train_0,train_1,train_2,train_3,train_4]\n",
    "TestList=[test_0,test_1,test_2,test_3,test_4]\n",
    "TrainNewList=[train_new_0,train_new_1,train_new_2,train_new_3,train_new_4]\n",
    "TestNewList=[test_new_0,test_new_1,test_new_2,test_new_3,test_new_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, auc, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def RunLRClassifier(TrainList,TestList,TrainNewList,TestNewList,D_features,X_features,Y_features):\n",
    "    LRModelsAUC=[]\n",
    "    LRTestPreds=[]\n",
    "    for i in range(0,len(TrainNewList)):\n",
    "        dft = pd.get_dummies(TrainNewList[i][D_features+X_features])\n",
    "        lr=LogisticRegression()\n",
    "        lr.fit(dft,TrainNewList[i][Y_features])\n",
    "        dft = pd.get_dummies(TestNewList[i][D_features+X_features])\n",
    "        proba=lr.predict_proba(dft)\n",
    "        ytrue=TestList[i][Y_features]\n",
    "        testauc=roc_auc_score(ytrue, proba[:, 1])\n",
    "        LRModelsAUC.append(testauc)\n",
    "        dft=TestList[i][D_features+X_features+Y_features]\n",
    "        dft['pred']=proba[:,1]\n",
    "        LRTestPreds.append(dft)\n",
    "    return LRModelsAUC,LRTestPreds\n",
    "\n",
    "def RunLRWithoutDClassifier(TrainList,TestList,D_features,X_features,Y_features):\n",
    "    LRModelsAUC=[]\n",
    "    LRTestPreds=[]\n",
    "    for i in range(0,len(TrainList)): \n",
    "        dft = pd.get_dummies(TrainList[i][X_features])\n",
    "        lr=LogisticRegression()\n",
    "        lr.fit(dft,TrainList[i][Y_features])\n",
    "        dft = pd.get_dummies(TestList[i][X_features])\n",
    "        proba=lr.predict_proba(dft)\n",
    "        ytrue=TestList[i][Y_features]\n",
    "        testauc=roc_auc_score(ytrue, proba[:, 1])\n",
    "        LRModelsAUC.append(testauc)\n",
    "        dft=TestList[i][D_features+X_features+Y_features]\n",
    "        dft['pred']=proba[:,1]\n",
    "        LRTestPreds.append(dft)\n",
    "    return LRModelsAUC,LRTestPreds\n",
    "\n",
    "def RunPlainLRClassifier(TrainList,TestList,D_features,X_features,Y_features):\n",
    "    LRModelsAUC=[]\n",
    "    LRTestPreds=[]\n",
    "    for i in range(0,len(TrainList)): \n",
    "        dft = pd.get_dummies(TrainList[i][D_features+X_features])\n",
    "        lr=LogisticRegression()\n",
    "        lr.fit(dft,TrainList[i][Y_features])\n",
    "        dft = pd.get_dummies(TestList[i][D_features+X_features])\n",
    "        proba=lr.predict_proba(dft)\n",
    "        ytrue=TestList[i][Y_features]\n",
    "        testauc=roc_auc_score(ytrue, proba[:, 1])\n",
    "        LRModelsAUC.append(testauc)\n",
    "        dft=TestList[i][D_features+X_features+Y_features]\n",
    "        dft['pred']=proba[:,1]\n",
    "        LRTestPreds.append(dft)\n",
    "    return LRModelsAUC,LRTestPreds\n",
    "\n",
    "def RunRFClassifier(TrainList,TestList,TrainNewList,TestNewList,D_features,X_features,Y_features):\n",
    "    RFModelsAUC=[]\n",
    "    RFTestPreds=[]\n",
    "    for i in range(0,len(TrainNewList)):\n",
    "        dft = pd.get_dummies(TrainNewList[i][D_features+X_features])\n",
    "        rf=RandomForestClassifier()\n",
    "        rf.fit(dft,TrainNewList[i][Y_features])\n",
    "        dft = pd.get_dummies(TestNewList[i][D_features+X_features])\n",
    "        proba=rf.predict_proba(dft)\n",
    "        ytrue=TestList[i][Y_features]\n",
    "        testauc=roc_auc_score(ytrue, proba[:, 1])\n",
    "        RFModelsAUC.append(testauc)\n",
    "        dft=TestList[i][D_features+X_features+Y_features]\n",
    "        dft['pred']=proba[:,1]\n",
    "        RFTestPreds.append(dft)\n",
    "    return RFModelsAUC,RFTestPreds\n",
    "\n",
    "def RunRFWithoutDClassifier(TrainList,TestList,D_features,X_features,Y_features):\n",
    "    RFModelsAUC=[]\n",
    "    RFTestPreds=[]\n",
    "    for i in range(0,len(TrainList)): \n",
    "        dft = pd.get_dummies(TrainList[i][X_features])\n",
    "        rf=RandomForestClassifier()\n",
    "        rf.fit(dft,TrainList[i][Y_features])\n",
    "        dft = pd.get_dummies(TestList[i][X_features])\n",
    "        proba=rf.predict_proba(dft)\n",
    "        ytrue=TestList[i][Y_features]\n",
    "        testauc=roc_auc_score(ytrue, proba[:, 1])\n",
    "        RFModelsAUC.append(testauc)\n",
    "        dft=TestList[i][D_features+X_features+Y_features]\n",
    "        dft['pred']=proba[:,1]\n",
    "        RFTestPreds.append(dft)\n",
    "    return RFModelsAUC,RFTestPreds\n",
    "\n",
    "def RunPlainRFClassifier(TrainList,TestList,D_features,X_features,Y_features):\n",
    "    RFModelsAUC=[]\n",
    "    RFTestPreds=[]\n",
    "    for i in range(0,len(TrainList)): \n",
    "        dft = pd.get_dummies(TrainList[i][D_features+X_features])\n",
    "        rf=RandomForestClassifier()\n",
    "        rf.fit(dft,TrainList[i][Y_features])\n",
    "        dft = pd.get_dummies(TestList[i][D_features+X_features])\n",
    "        proba=rf.predict_proba(dft)\n",
    "        ytrue=TestList[i][Y_features]\n",
    "        testauc=roc_auc_score(ytrue, proba[:, 1])\n",
    "        RFModelsAUC.append(testauc)\n",
    "        dft=TestList[i][D_features+X_features+Y_features]\n",
    "        dft['pred']=proba[:,1]\n",
    "        RFTestPreds.append(dft)\n",
    "    return RFModelsAUC,RFTestPreds\n",
    "\n",
    "\n",
    "def RunNBClassifier(TrainList,TestList,TrainNewList,TestNewList,D_features,X_features,Y_features):\n",
    "    NBModelsAUC=[]\n",
    "    NBTestPreds=[]\n",
    "    for i in range(0,len(TrainNewList)):\n",
    "        dft = pd.get_dummies(TrainNewList[i][D_features+X_features])\n",
    "        nb=MultinomialNB()\n",
    "        nb.fit(dft,TrainNewList[i][Y_features])\n",
    "        dft = pd.get_dummies(TestNewList[i][D_features+X_features])\n",
    "        proba=nb.predict_proba(dft)\n",
    "        ytrue=TestList[i][Y_features]\n",
    "        testauc=roc_auc_score(ytrue, proba[:, 1])\n",
    "        NBModelsAUC.append(testauc)\n",
    "        dft=TestList[i][D_features+X_features+Y_features]\n",
    "        dft['pred']=proba[:,1]\n",
    "        NBTestPreds.append(dft)\n",
    "    return NBModelsAUC,NBTestPreds\n",
    "\n",
    "def RunNBWithoutDClassifier(TrainList,TestList,D_features,X_features,Y_features):\n",
    "    NBModelsAUC=[]\n",
    "    NBTestPreds=[]\n",
    "    for i in range(0,len(TrainList)): \n",
    "        dft = pd.get_dummies(TrainList[i][X_features])\n",
    "        nb=MultinomialNB()\n",
    "        nb.fit(dft,TrainList[i][Y_features])\n",
    "        dft = pd.get_dummies(TestList[i][X_features])\n",
    "        proba=nb.predict_proba(dft)\n",
    "        ytrue=TestList[i][Y_features]\n",
    "        testauc=roc_auc_score(ytrue, proba[:, 1])\n",
    "        NBModelsAUC.append(testauc)\n",
    "        dft=TestList[i][D_features+X_features+Y_features]\n",
    "        dft['pred']=proba[:,1]\n",
    "        NBTestPreds.append(dft)\n",
    "    return NBModelsAUC,NBTestPreds\n",
    "\n",
    "def RunPlainNBClassifier(TrainList,TestList,D_features,X_features,Y_features):\n",
    "    NBModelsAUC=[]\n",
    "    NBTestPreds=[]\n",
    "    for i in range(0,len(TrainList)): \n",
    "        dft = pd.get_dummies(TrainList[i][D_features+X_features])\n",
    "        nb=MultinomialNB()\n",
    "        nb.fit(dft,TrainList[i][Y_features])\n",
    "        dft = pd.get_dummies(TestList[i][D_features+X_features])\n",
    "        proba=nb.predict_proba(dft)\n",
    "        ytrue=TestList[i][Y_features]\n",
    "        testauc=roc_auc_score(ytrue, proba[:, 1])\n",
    "        NBModelsAUC.append(testauc)\n",
    "        dft=TestList[i][D_features+X_features+Y_features]\n",
    "        dft['pred']=proba[:,1]\n",
    "        NBTestPreds.append(dft)\n",
    "    return NBModelsAUC,NBTestPreds\n",
    "\n",
    "\n",
    "def RunSVClassifier(TrainList,TestList,TrainNewList,TestNewList,D_features,X_features,Y_features):\n",
    "    SVModelsAUC=[]\n",
    "    SVTestPreds=[]\n",
    "    for i in range(0,len(TrainNewList)):\n",
    "        dft = pd.get_dummies(TrainNewList[i][D_features+X_features])\n",
    "        svc=SVC(probability=True, random_state=0, C=1.0)\n",
    "        svc.fit(dft,TrainNewList[i][Y_features])\n",
    "        dft = pd.get_dummies(TestNewList[i][D_features+X_features])\n",
    "        proba=svc.predict_proba(dft)\n",
    "        ytrue=TestList[i][Y_features]\n",
    "        testauc=roc_auc_score(ytrue, proba[:, 1])\n",
    "        SVModelsAUC.append(testauc)\n",
    "        dft=TestList[i][D_features+X_features+Y_features]\n",
    "        dft['pred']=proba[:,1]\n",
    "        SVTestPreds.append(dft)\n",
    "    return SVModelsAUC,SVTestPreds\n",
    "\n",
    "def RunSVWithoutDClassifier(TrainList,TestList,D_features,X_features,Y_features):\n",
    "    SVModelsAUC=[]\n",
    "    SVTestPreds=[]\n",
    "    for i in range(0,len(TrainList)): \n",
    "        dft = pd.get_dummies(TrainList[i][X_features])\n",
    "        svc = SVC(kernel='linear',probability=True)\n",
    "        svc.fit(dft,TrainList[i][Y_features])\n",
    "        dft = pd.get_dummies(TestList[i][X_features])\n",
    "        proba=svc.predict_proba(dft)\n",
    "        ytrue=TestList[i][Y_features]\n",
    "        testauc=roc_auc_score(ytrue, proba[:, 1])\n",
    "        SVModelsAUC.append(testauc)\n",
    "        dft=TestList[i][D_features+X_features+Y_features]\n",
    "        dft['pred']=proba[:,1]\n",
    "        SVTestPreds.append(dft)\n",
    "    return SVModelsAUC,SVTestPreds\n",
    "\n",
    "def RunPlainSVClassifier(TrainList,TestList,D_features,X_features,Y_features):\n",
    "    SVModelsAUC=[]\n",
    "    SVTestPreds=[]\n",
    "    for i in range(0,len(TrainList)): \n",
    "        dft = pd.get_dummies(TrainList[i][D_features+X_features])\n",
    "        svc = SVC(kernel='linear',probability=True)\n",
    "        svc.fit(dft,TrainList[i][Y_features])\n",
    "        dft = pd.get_dummies(TestList[i][D_features+X_features])\n",
    "        proba=svc.predict_proba(dft)\n",
    "        ytrue=TestList[i][Y_features]\n",
    "        testauc=roc_auc_score(ytrue, proba[:, 1])\n",
    "        SVModelsAUC.append(testauc)\n",
    "        dft=TestList[i][D_features+X_features+Y_features]\n",
    "        dft['pred']=proba[:,1]\n",
    "        SVTestPreds.append(dft)\n",
    "    return SVModelsAUC,SVTestPreds\n",
    "\n",
    "def ComputeDiscrimination(LRTestPreds,D_features):\n",
    "    test_disc=[]\n",
    "    for i in range(0,len(LRTestPreds)):\n",
    "        mean = LRTestPreds[i].groupby(D_features)['pred'].mean()\n",
    "        v = mean.values\n",
    "        v = v.reshape(len(v),1)\n",
    "        ratio_df = pd.DataFrame(v/v.transpose(),index=mean.index,columns=mean.index )\n",
    "        ratio_df_arr=np.asarray(np.abs(1-ratio_df))\n",
    "        maxdisc=np.amax(ratio_df_arr)\n",
    "        test_disc.append(maxdisc)   \n",
    "    return test_disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#LRres=RunLRClassifier(TrainList,TestList,TrainNewList,TestNewList,D_features,X_features,Y_features)\n",
    "#LRres=RunPlainLRClassifier(TrainList,TestList,D_features,X_features,Y_features)\n",
    "LRres=RunLRWithoutDClassifier(TrainList,TestList,D_features,X_features,Y_features)\n",
    "LRDisc=ComputeDiscrimination(LRres[1],D_features)\n",
    "\n",
    "#RFres=RunRFClassifier(TrainList,TestList,TrainNewList,TestNewList,D_features,X_features,Y_features)\n",
    "#RFres=RunPlainRFClassifier(TrainList,TestList,D_features,X_features,Y_features)\n",
    "#RFres=RunRFWithoutDClassifier(TrainList,TestList,D_features,X_features,Y_features)\n",
    "#RFDisc=ComputeDiscrimination(RFres[1],D_features)\n",
    "\n",
    "#NBres=RunNBClassifier(TrainList,TestList,TrainNewList,TestNewList,D_features,X_features,Y_features)\n",
    "#NBres=RunPlainNBClassifier(TrainList,TestList,D_features,X_features,Y_features)\n",
    "#NBres=RunNBWithoutDClassifier(TrainList,TestList,D_features,X_features,Y_features)\n",
    "#NBDisc=ComputeDiscrimination(NBres[1],D_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "LRAUC4=np.asarray(LRres[0])\n",
    "LR_mean4 = np.mean(LRAUC4)\n",
    "\n",
    "zemelauc=np.asarray([0.676842373423,0.693,0.687,0.693,0.699])\n",
    "#zemelauc=np.asarray([0.706,0.682,0.701,0.705,0.706])\n",
    "zemel_mean=np.mean(zemelauc)\n",
    "\n",
    "# standard deviation\n",
    "LR_std4 = np.std(LRAUC4)\n",
    "zemel_std=np.std(zemelauc)\n",
    "\n",
    "LRDisc4=np.asarray(LRDisc)\n",
    "LRdisc_mean4 = np.mean(LRDisc4)\n",
    "LRdisc_std4=np.std(LRDisc4)\n",
    "\n",
    "zemel_disc=np.asarray([0.0197,0.0122,0.0149,0.046])\n",
    "#zemel_disc=np.asarray([0.265,0.375,0.284,0.303,0.330])\n",
    "zemel_disc_mean=np.mean(zemel_disc)\n",
    "zemel_disc_std=np.std(zemel_disc)\n",
    "\n",
    "# standard error\n",
    "#RF_se3 = RF_std3 / np.sqrt(RFAUC3.size)\n",
    "\n",
    "#zemel_se=zemel_std/np.sqrt(zemelauc.size)\n",
    "\n",
    "#zemel_antidiscrim=0\n",
    "#zemelaccuracyvals=np.asarray([0.76,0.78])\n",
    "#zemel_mean=np.mean(zemelaccuracyvals)\n",
    "#zemel_std=np.std(zemelaccuracyvals)\n",
    "\n",
    "#dof = LRAUC5.size - 1         # degrees of freedom\n",
    "#dof=zemelauc.size-1\n",
    "alpha = 1.0 - 0.95\n",
    "#conf_interval = t.ppf(1-alpha/2., dof) * LR_std1*np.sqrt(1.+1./LRAUC1.size)\n",
    "#conf_interval = t.ppf(1-alpha/2., dof) * zemel_std*np.sqrt(1.+1./zemelauc.size)\n",
    "\n",
    "fig = plt.gca()\n",
    "font_options={'family' : 'sans-serif'}\n",
    "plt.rc('font', **font_options)\n",
    "\n",
    "plt.errorbar(LRdisc_mean2, LR_mean2, xerr=LRdisc_std2, yerr=LR_std2, fmt='-o') #RF\n",
    "plt.errorbar(LRdisc_mean4, LR_mean4, xerr=LRdisc_std4, yerr=LR_std4, fmt='-o') # RF + Dropping D\n",
    "plt.errorbar(zemel_disc_mean, zemel_mean, xerr=zemel_disc_std, yerr=zemel_std, fmt='-o') # Zemel\n",
    "plt.errorbar(LRdisc_mean1, LR_mean1, xerr=LRdisc_std1, yerr=LR_std1, fmt='-o') # RF + 0.05 (eps)\n",
    "plt.errorbar(LRdisc_mean3, LR_mean3, xerr=LRdisc_std3, yerr=LR_std3, fmt='-o') # RF + 0.1 (eps)\n",
    "\n",
    "#fig.axes.get_xaxis().set_visible(False)\n",
    "fig.spines[\"top\"].set_visible(False)  \n",
    "fig.spines[\"right\"].set_visible(False)  \n",
    "plt.tick_params(axis=\"both\", which=\"both\", bottom=\"off\", top=\"off\",  \n",
    "                labelbottom=\"on\", left=\"on\", right=\"off\", labelleft=\"on\")  \n",
    "\n",
    "plt.legend(['LR','LR + Dropping D','LFR','LR + Our approach(.05)','LR + Our approach(.1)'], \n",
    "           loc='best',fancybox=True)\n",
    "\n",
    "plt.ylabel('AUC')\n",
    "plt.xlabel('Discrimination')\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "plt.savefig('nips_plots/aucvsdiscLR_new_zemel_best.png',dpi=400,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
